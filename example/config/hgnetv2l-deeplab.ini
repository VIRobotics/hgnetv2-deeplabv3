[base]

# ----------------------------------------------------------------------------------------------------------------------------#
#   训练分为两个阶段，分别是冻结阶段和解冻阶段。设置冻结阶段是为了满足机器性能不足的同学的训练需求。
#   冻结训练需要的显存较小，显卡非常差的情况下，可设置Freeze_Epoch等于UnFreeze_Epoch，此时仅仅进行冻结训练。
#
#   在此提供若干参数设置建议，各位训练者根据自己的需求进行灵活调整：
#   （一）从整个模型的预训练权重开始训练：
#       Adam：
#           Init_Epoch = 0，Freeze_Epoch = 50，UnFreeze_Epoch = 100，Freeze_Train = True，optimizer_type = 'adam'，Init_lr = 5e-4，weight_decay = 0。（冻结）
#           Init_Epoch = 0，UnFreeze_Epoch = 100，Freeze_Train = False，optimizer_type = 'adam'，Init_lr = 5e-4，weight_decay = 0。（不冻结）
#       SGD：
#           Init_Epoch = 0，Freeze_Epoch = 50，UnFreeze_Epoch = 100，Freeze_Train = True，optimizer_type = 'sgd'，Init_lr = 7e-3，weight_decay = 1e-4。（冻结）
#           Init_Epoch = 0，UnFreeze_Epoch = 100，Freeze_Train = False，optimizer_type = 'sgd'，Init_lr = 7e-3，weight_decay = 1e-4。（不冻结）
#       其中：UnFreeze_Epoch可以在100-300之间调整。
#   （二）从主干网络的预训练权重开始训练：
#       Adam：
#           Init_Epoch = 0，Freeze_Epoch = 50，UnFreeze_Epoch = 100，Freeze_Train = True，optimizer_type = 'adam'，Init_lr = 5e-4，weight_decay = 0。（冻结）
#           Init_Epoch = 0，UnFreeze_Epoch = 100，Freeze_Train = False，optimizer_type = 'adam'，Init_lr = 5e-4，weight_decay = 0。（不冻结）
#       SGD：
#           Init_Epoch = 0，Freeze_Epoch = 50，UnFreeze_Epoch = 120，Freeze_Train = True，optimizer_type = 'sgd'，Init_lr = 7e-3，weight_decay = 1e-4。（冻结）
#           Init_Epoch = 0，UnFreeze_Epoch = 120，Freeze_Train = False，optimizer_type = 'sgd'，Init_lr = 7e-3，weight_decay = 1e-4。（不冻结）
#       其中：由于从主干网络的预训练权重开始训练，主干的权值不一定适合语义分割，需要更多的训练跳出局部最优解。
#             UnFreeze_Epoch可以在120-300之间调整。
#             Adam相较于SGD收敛的快一些。因此UnFreeze_Epoch理论上可以小一点，但依然推荐更多的Epoch。
#   （三）batch_size的设置：
#       在显卡能够接受的范围内，以大为好。显存不足与数据集大小无关，提示显存不足（OOM或者CUDA out of memory）请调小batch_size。
#       受到BatchNorm层影响，batch_size最小为2，不能为1。
#       正常情况下Freeze_batch_size建议为Unfreeze_batch_size的1-2倍。不建议设置的差距过大，因为关系到学习率的自动调整。
# ----------------------------------------------------------------------------------------------------------------------------#
# ------------------------------------------------------------------#
#   冻结阶段训练参数
#   此时模型的主干被冻结了，特征提取网络不发生改变
#   占用的显存较小，仅对网络进行微调
#   Init_Epoch          模型当前开始的训练世代，其值可以大于Freeze_Epoch，如设置：
#                       Init_Epoch = 60、Freeze_Epoch = 50、UnFreeze_Epoch = 100
#                       会跳过冻结阶段，直接从60代开始，并调整对应的学习率。
#                       （断点续练时使用）
#   Freeze_Epoch        模型冻结训练的Freeze_Epoch
#                       (当Freeze_Train=False时失效)
#   Freeze_batch_size   模型冻结训练的batch_size
#                       (当Freeze_Train=False时失效)
# ------------------------------------------------------------------#
frozen_batch-size=24
unfrozen_batch-size=16
frozen_epoch=50
unfrozen_epoch=100
fp16=true
num_workers=4
#路径设置
##相对路径的话 此处调用的是相对于配置文件的路径
dataset_path=VOCdevkit
save_path=hgnetv2l_deeplab
# -----------------------------------------------------#
#   num_classes     训练自己的数据集必须要修改的
#                   自己需要的分类个数+1，如2+1
# -----------------------------------------------------#
num_classes=21
# ---------------------------------#
#   所使用的的主干网络：
#   mobilenet
#   xception
#   hgnetv2l | hgnetv2x
#   yolov8s | yolov8m
# ---------------------------------#
backbone=hgnetv2l
#   输入图片的大小
image_size=512
# ---------------------------------#
#   所使用的的分割头：
#   ASPP
#   transformer
# ---------------------------------#
header = ASPP
arch = lab
[advance]
# ------------------------------------------------------------------#
#   DiceLoss建议选项：
#   种类少（几类）时，设置为True
#   种类多（十几类）时，如果batch_size比较大（10以上），那么设置为True
#   种类多（十几类）时，如果batch_size比较小（10以下），那么设置为False
# ------------------------------------------------------------------#
dice_loss=true
#   是否使用focal loss来防止正负样本不平衡
focal_loss=false
#init_lr=7e-3
#min_lr_mutliply=0.01
#可选8 或16 越小效果越好 显存占用也越大
downsample_factor=16